// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License"). You may
// not use this file except in compliance with the License. A copy of the
// License is located at
//
//     http://aws.amazon.com/apache2.0/
//
// or in the "license" file accompanying this file. This file is distributed
// on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
// express or implied. See the License for the specific language governing
// permissions and limitations under the License.

// Code generated by ack-generate. DO NOT EDIT.

package serverless_cluster

import (
	"context"
	"errors"
	"fmt"
	"math"
	"reflect"
	"strings"

	ackv1alpha1 "github.com/aws-controllers-k8s/runtime/apis/core/v1alpha1"
	ackcompare "github.com/aws-controllers-k8s/runtime/pkg/compare"
	ackcondition "github.com/aws-controllers-k8s/runtime/pkg/condition"
	ackerr "github.com/aws-controllers-k8s/runtime/pkg/errors"
	ackrequeue "github.com/aws-controllers-k8s/runtime/pkg/requeue"
	ackrtlog "github.com/aws-controllers-k8s/runtime/pkg/runtime/log"
	"github.com/aws/aws-sdk-go-v2/aws"
	svcsdk "github.com/aws/aws-sdk-go-v2/service/kafka"
	svcsdktypes "github.com/aws/aws-sdk-go-v2/service/kafka/types"
	smithy "github.com/aws/smithy-go"
	corev1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"

	svcapitypes "github.com/aws-controllers-k8s/kafka-controller/apis/v1alpha1"
)

// Hack to avoid import errors during build...
var (
	_ = &metav1.Time{}
	_ = strings.ToLower("")
	_ = &svcsdk.Client{}
	_ = &svcapitypes.ServerlessCluster{}
	_ = ackv1alpha1.AWSAccountID("")
	_ = &ackerr.NotFound
	_ = &ackcondition.NotManagedMessage
	_ = &reflect.Value{}
	_ = fmt.Sprintf("")
	_ = &ackrequeue.NoRequeue{}
	_ = &aws.Config{}
)

// sdkFind returns SDK-specific information about a supplied resource
func (rm *resourceManager) sdkFind(
	ctx context.Context,
	r *resource,
) (latest *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkFind")
	defer func() {
		exit(err)
	}()
	// If any required fields in the input shape are missing, AWS resource is
	// not created yet. Return NotFound here to indicate to callers that the
	// resource isn't yet created.
	if rm.requiredFieldsMissingFromReadOneInput(r) {
		return nil, ackerr.NotFound
	}

	input, err := rm.newDescribeRequestPayload(r)
	if err != nil {
		return nil, err
	}

	var resp *svcsdk.DescribeClusterV2Output
	resp, err = rm.sdkapi.DescribeClusterV2(ctx, input)
	rm.metrics.RecordAPICall("READ_ONE", "DescribeClusterV2", err)
	if err != nil {
		var awsErr smithy.APIError
		if errors.As(err, &awsErr) && awsErr.ErrorCode() == "NotFoundException" {
			return nil, ackerr.NotFound
		}
		return nil, err
	}

	// Merge in the information we read from the API call above to the copy of
	// the original Kubernetes object we passed to the function
	ko := r.ko.DeepCopy()

	if ko.Status.ACKResourceMetadata == nil {
		ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if resp.ClusterInfo.ClusterArn != nil {
		arn := ackv1alpha1.AWSResourceName(*resp.ClusterInfo.ClusterArn)
		ko.Status.ACKResourceMetadata.ARN = &arn
	}
	if resp.ClusterInfo.ClusterName != nil {
		ko.Spec.Name = resp.ClusterInfo.ClusterName
	} else {
		ko.Spec.Name = nil
	}
	if resp.ClusterInfo.ClusterType != "" {
		ko.Status.Type = aws.String(string(resp.ClusterInfo.ClusterType))
	} else {
		ko.Status.Type = nil
	}
	if resp.ClusterInfo.CurrentVersion != nil {
		ko.Status.CurrentVersion = resp.ClusterInfo.CurrentVersion
	} else {
		ko.Status.CurrentVersion = nil
	}
	if resp.ClusterInfo.Provisioned != nil {
		f6 := &svcapitypes.ProvisionedRequest{}
		if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo != nil {
			f6f0 := &svcapitypes.BrokerNodeGroupInfo{}
			if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.BrokerAZDistribution != "" {
				f6f0.BrokerAZDistribution = aws.String(string(resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.BrokerAZDistribution))
			}
			if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.ClientSubnets != nil {
				f6f0.ClientSubnets = aws.StringSlice(resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.ClientSubnets)
			}
			if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.ConnectivityInfo != nil {
				f6f0f2 := &svcapitypes.ConnectivityInfo{}
				if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.ConnectivityInfo.PublicAccess != nil {
					f6f0f2f0 := &svcapitypes.PublicAccess{}
					if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.ConnectivityInfo.PublicAccess.Type != nil {
						f6f0f2f0.Type = resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.ConnectivityInfo.PublicAccess.Type
					}
					f6f0f2.PublicAccess = f6f0f2f0
				}
				f6f0.ConnectivityInfo = f6f0f2
			}
			if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.InstanceType != nil {
				f6f0.InstanceType = resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.InstanceType
			}
			if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.SecurityGroups != nil {
				f6f0.SecurityGroups = aws.StringSlice(resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.SecurityGroups)
			}
			if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.StorageInfo != nil {
				f6f0f5 := &svcapitypes.StorageInfo{}
				if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.StorageInfo.EbsStorageInfo != nil {
					f6f0f5f0 := &svcapitypes.EBSStorageInfo{}
					if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.StorageInfo.EbsStorageInfo.ProvisionedThroughput != nil {
						f6f0f5f0f0 := &svcapitypes.ProvisionedThroughput{}
						if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.StorageInfo.EbsStorageInfo.ProvisionedThroughput.Enabled != nil {
							f6f0f5f0f0.Enabled = resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.StorageInfo.EbsStorageInfo.ProvisionedThroughput.Enabled
						}
						if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.StorageInfo.EbsStorageInfo.ProvisionedThroughput.VolumeThroughput != nil {
							volumeThroughputCopy := int64(*resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.StorageInfo.EbsStorageInfo.ProvisionedThroughput.VolumeThroughput)
							f6f0f5f0f0.VolumeThroughput = &volumeThroughputCopy
						}
						f6f0f5f0.ProvisionedThroughput = f6f0f5f0f0
					}
					if resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.StorageInfo.EbsStorageInfo.VolumeSize != nil {
						volumeSizeCopy := int64(*resp.ClusterInfo.Provisioned.BrokerNodeGroupInfo.StorageInfo.EbsStorageInfo.VolumeSize)
						f6f0f5f0.VolumeSize = &volumeSizeCopy
					}
					f6f0f5.EBSStorageInfo = f6f0f5f0
				}
				f6f0.StorageInfo = f6f0f5
			}
			f6.BrokerNodeGroupInfo = f6f0
		}
		if resp.ClusterInfo.Provisioned.ClientAuthentication != nil {
			f6f1 := &svcapitypes.ClientAuthentication{}
			if resp.ClusterInfo.Provisioned.ClientAuthentication.Sasl != nil {
				f6f1f0 := &svcapitypes.SASL{}
				if resp.ClusterInfo.Provisioned.ClientAuthentication.Sasl.Iam != nil {
					f6f1f0f0 := &svcapitypes.IAM{}
					if resp.ClusterInfo.Provisioned.ClientAuthentication.Sasl.Iam.Enabled != nil {
						f6f1f0f0.Enabled = resp.ClusterInfo.Provisioned.ClientAuthentication.Sasl.Iam.Enabled
					}
					f6f1f0.IAM = f6f1f0f0
				}
				if resp.ClusterInfo.Provisioned.ClientAuthentication.Sasl.Scram != nil {
					f6f1f0f1 := &svcapitypes.SCRAM{}
					if resp.ClusterInfo.Provisioned.ClientAuthentication.Sasl.Scram.Enabled != nil {
						f6f1f0f1.Enabled = resp.ClusterInfo.Provisioned.ClientAuthentication.Sasl.Scram.Enabled
					}
					f6f1f0.SCRAM = f6f1f0f1
				}
				f6f1.SASL = f6f1f0
			}
			if resp.ClusterInfo.Provisioned.ClientAuthentication.Tls != nil {
				f6f1f1 := &svcapitypes.TLS{}
				if resp.ClusterInfo.Provisioned.ClientAuthentication.Tls.CertificateAuthorityArnList != nil {
					f6f1f1.CertificateAuthorityARNList = aws.StringSlice(resp.ClusterInfo.Provisioned.ClientAuthentication.Tls.CertificateAuthorityArnList)
				}
				if resp.ClusterInfo.Provisioned.ClientAuthentication.Tls.Enabled != nil {
					f6f1f1.Enabled = resp.ClusterInfo.Provisioned.ClientAuthentication.Tls.Enabled
				}
				f6f1.TLS = f6f1f1
			}
			if resp.ClusterInfo.Provisioned.ClientAuthentication.Unauthenticated != nil {
				f6f1f2 := &svcapitypes.Unauthenticated{}
				if resp.ClusterInfo.Provisioned.ClientAuthentication.Unauthenticated.Enabled != nil {
					f6f1f2.Enabled = resp.ClusterInfo.Provisioned.ClientAuthentication.Unauthenticated.Enabled
				}
				f6f1.Unauthenticated = f6f1f2
			}
			f6.ClientAuthentication = f6f1
		}
		if resp.ClusterInfo.Provisioned.EncryptionInfo != nil {
			f6f4 := &svcapitypes.EncryptionInfo{}
			if resp.ClusterInfo.Provisioned.EncryptionInfo.EncryptionAtRest != nil {
				f6f4f0 := &svcapitypes.EncryptionAtRest{}
				if resp.ClusterInfo.Provisioned.EncryptionInfo.EncryptionAtRest.DataVolumeKMSKeyId != nil {
					f6f4f0.DataVolumeKMSKeyID = resp.ClusterInfo.Provisioned.EncryptionInfo.EncryptionAtRest.DataVolumeKMSKeyId
				}
				f6f4.EncryptionAtRest = f6f4f0
			}
			if resp.ClusterInfo.Provisioned.EncryptionInfo.EncryptionInTransit != nil {
				f6f4f1 := &svcapitypes.EncryptionInTransit{}
				if resp.ClusterInfo.Provisioned.EncryptionInfo.EncryptionInTransit.ClientBroker != "" {
					f6f4f1.ClientBroker = aws.String(string(resp.ClusterInfo.Provisioned.EncryptionInfo.EncryptionInTransit.ClientBroker))
				}
				if resp.ClusterInfo.Provisioned.EncryptionInfo.EncryptionInTransit.InCluster != nil {
					f6f4f1.InCluster = resp.ClusterInfo.Provisioned.EncryptionInfo.EncryptionInTransit.InCluster
				}
				f6f4.EncryptionInTransit = f6f4f1
			}
			f6.EncryptionInfo = f6f4
		}
		if resp.ClusterInfo.Provisioned.EnhancedMonitoring != "" {
			f6.EnhancedMonitoring = aws.String(string(resp.ClusterInfo.Provisioned.EnhancedMonitoring))
		}
		if resp.ClusterInfo.Provisioned.LoggingInfo != nil {
			f6f6 := &svcapitypes.LoggingInfo{}
			if resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs != nil {
				f6f6f0 := &svcapitypes.BrokerLogs{}
				if resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.CloudWatchLogs != nil {
					f6f6f0f0 := &svcapitypes.CloudWatchLogs{}
					if resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.CloudWatchLogs.Enabled != nil {
						f6f6f0f0.Enabled = resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.CloudWatchLogs.Enabled
					}
					if resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.CloudWatchLogs.LogGroup != nil {
						f6f6f0f0.LogGroup = resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.CloudWatchLogs.LogGroup
					}
					f6f6f0.CloudWatchLogs = f6f6f0f0
				}
				if resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.Firehose != nil {
					f6f6f0f1 := &svcapitypes.Firehose{}
					if resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.Firehose.DeliveryStream != nil {
						f6f6f0f1.DeliveryStream = resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.Firehose.DeliveryStream
					}
					if resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.Firehose.Enabled != nil {
						f6f6f0f1.Enabled = resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.Firehose.Enabled
					}
					f6f6f0.Firehose = f6f6f0f1
				}
				if resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.S3 != nil {
					f6f6f0f2 := &svcapitypes.S3{}
					if resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.S3.Bucket != nil {
						f6f6f0f2.Bucket = resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.S3.Bucket
					}
					if resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.S3.Enabled != nil {
						f6f6f0f2.Enabled = resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.S3.Enabled
					}
					if resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.S3.Prefix != nil {
						f6f6f0f2.Prefix = resp.ClusterInfo.Provisioned.LoggingInfo.BrokerLogs.S3.Prefix
					}
					f6f6f0.S3 = f6f6f0f2
				}
				f6f6.BrokerLogs = f6f6f0
			}
			f6.LoggingInfo = f6f6
		}
		if resp.ClusterInfo.Provisioned.NumberOfBrokerNodes != nil {
			numberOfBrokerNodesCopy := int64(*resp.ClusterInfo.Provisioned.NumberOfBrokerNodes)
			f6.NumberOfBrokerNodes = &numberOfBrokerNodesCopy
		}
		if resp.ClusterInfo.Provisioned.OpenMonitoring != nil {
			f6f8 := &svcapitypes.OpenMonitoringInfo{}
			if resp.ClusterInfo.Provisioned.OpenMonitoring.Prometheus != nil {
				f6f8f0 := &svcapitypes.PrometheusInfo{}
				if resp.ClusterInfo.Provisioned.OpenMonitoring.Prometheus.JmxExporter != nil {
					f6f8f0f0 := &svcapitypes.JmxExporterInfo{}
					if resp.ClusterInfo.Provisioned.OpenMonitoring.Prometheus.JmxExporter.EnabledInBroker != nil {
						f6f8f0f0.EnabledInBroker = resp.ClusterInfo.Provisioned.OpenMonitoring.Prometheus.JmxExporter.EnabledInBroker
					}
					f6f8f0.JmxExporter = f6f8f0f0
				}
				if resp.ClusterInfo.Provisioned.OpenMonitoring.Prometheus.NodeExporter != nil {
					f6f8f0f1 := &svcapitypes.NodeExporterInfo{}
					if resp.ClusterInfo.Provisioned.OpenMonitoring.Prometheus.NodeExporter.EnabledInBroker != nil {
						f6f8f0f1.EnabledInBroker = resp.ClusterInfo.Provisioned.OpenMonitoring.Prometheus.NodeExporter.EnabledInBroker
					}
					f6f8f0.NodeExporter = f6f8f0f1
				}
				f6f8.Prometheus = f6f8f0
			}
			f6.OpenMonitoring = f6f8
		}
		if resp.ClusterInfo.Provisioned.StorageMode != "" {
			f6.StorageMode = aws.String(string(resp.ClusterInfo.Provisioned.StorageMode))
		}
		ko.Spec.Provisioned = f6
	} else {
		ko.Spec.Provisioned = nil
	}
	if resp.ClusterInfo.Serverless != nil {
		f7 := &svcapitypes.ServerlessRequest{}
		if resp.ClusterInfo.Serverless.ClientAuthentication != nil {
			f7f0 := &svcapitypes.ServerlessClientAuthentication{}
			if resp.ClusterInfo.Serverless.ClientAuthentication.Sasl != nil {
				f7f0f0 := &svcapitypes.ServerlessSASL{}
				if resp.ClusterInfo.Serverless.ClientAuthentication.Sasl.Iam != nil {
					f7f0f0f0 := &svcapitypes.IAM{}
					if resp.ClusterInfo.Serverless.ClientAuthentication.Sasl.Iam.Enabled != nil {
						f7f0f0f0.Enabled = resp.ClusterInfo.Serverless.ClientAuthentication.Sasl.Iam.Enabled
					}
					f7f0f0.IAM = f7f0f0f0
				}
				f7f0.SASL = f7f0f0
			}
			f7.ClientAuthentication = f7f0
		}
		if resp.ClusterInfo.Serverless.VpcConfigs != nil {
			f7f1 := []*svcapitypes.VPCConfig{}
			for _, f7f1iter := range resp.ClusterInfo.Serverless.VpcConfigs {
				f7f1elem := &svcapitypes.VPCConfig{}
				if f7f1iter.SecurityGroupIds != nil {
					f7f1elem.SecurityGroupIDs = aws.StringSlice(f7f1iter.SecurityGroupIds)
				}
				if f7f1iter.SubnetIds != nil {
					f7f1elem.SubnetIDs = aws.StringSlice(f7f1iter.SubnetIds)
				}
				f7f1 = append(f7f1, f7f1elem)
			}
			f7.VPCConfigs = f7f1
		}
		ko.Spec.Serverless = f7
	} else {
		ko.Spec.Serverless = nil
	}
	if resp.ClusterInfo.State != "" {
		ko.Status.State = aws.String(string(resp.ClusterInfo.State))
	} else {
		ko.Status.State = nil
	}
	if resp.ClusterInfo.Tags != nil {
		ko.Spec.Tags = aws.StringMap(resp.ClusterInfo.Tags)
	} else {
		ko.Spec.Tags = nil
	}

	rm.setStatusDefaults(ko)
	if resp.ClusterInfo.Provisioned.CurrentBrokerSoftwareInfo != nil && resp.ClusterInfo.Provisioned.CurrentBrokerSoftwareInfo.KafkaVersion != nil {
		ko.Spec.Provisioned.KafkaVersion = resp.ClusterInfo.Provisioned.CurrentBrokerSoftwareInfo.KafkaVersion
	}
	if resp.ClusterInfo.CurrentVersion != nil {
		ko.Status.CurrentVersion = resp.ClusterInfo.CurrentVersion
	} else {
		ko.Status.CurrentVersion = nil
	}
	if !serverlessClusterActive(&resource{ko}) {
		// Setting resource synced condition to false will trigger a requeue of
		// the resource. No need to return a requeue error here.
		ackcondition.SetSynced(&resource{ko}, corev1.ConditionFalse, nil, nil)
	} else {
		ackcondition.SetSynced(&resource{ko}, corev1.ConditionTrue, nil, nil)
		ko.Spec.AssociatedSCRAMSecrets, err = rm.getAssociatedScramSecrets(ctx, &resource{ko})
		if err != nil {
			return nil, err
		}
	}
	return &resource{ko}, nil
}

// requiredFieldsMissingFromReadOneInput returns true if there are any fields
// for the ReadOne Input shape that are required but not present in the
// resource's Spec or Status
func (rm *resourceManager) requiredFieldsMissingFromReadOneInput(
	r *resource,
) bool {
	return (r.ko.Status.ACKResourceMetadata == nil || r.ko.Status.ACKResourceMetadata.ARN == nil)

}

// newDescribeRequestPayload returns SDK-specific struct for the HTTP request
// payload of the Describe API call for the resource
func (rm *resourceManager) newDescribeRequestPayload(
	r *resource,
) (*svcsdk.DescribeClusterV2Input, error) {
	res := &svcsdk.DescribeClusterV2Input{}

	if r.ko.Status.ACKResourceMetadata != nil && r.ko.Status.ACKResourceMetadata.ARN != nil {
		res.ClusterArn = (*string)(r.ko.Status.ACKResourceMetadata.ARN)
	}

	return res, nil
}

// sdkCreate creates the supplied resource in the backend AWS service API and
// returns a copy of the resource with resource fields (in both Spec and
// Status) filled in with values from the CREATE API operation's Output shape.
func (rm *resourceManager) sdkCreate(
	ctx context.Context,
	desired *resource,
) (created *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkCreate")
	defer func() {
		exit(err)
	}()
	input, err := rm.newCreateRequestPayload(ctx, desired)
	if err != nil {
		return nil, err
	}

	var resp *svcsdk.CreateClusterV2Output
	_ = resp
	resp, err = rm.sdkapi.CreateClusterV2(ctx, input)
	rm.metrics.RecordAPICall("CREATE", "CreateClusterV2", err)
	if err != nil {
		return nil, err
	}
	// Merge in the information we read from the API call above to the copy of
	// the original Kubernetes object we passed to the function
	ko := desired.ko.DeepCopy()

	if ko.Status.ACKResourceMetadata == nil {
		ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if resp.ClusterArn != nil {
		arn := ackv1alpha1.AWSResourceName(*resp.ClusterArn)
		ko.Status.ACKResourceMetadata.ARN = &arn
	}
	if resp.ClusterName != nil {
		ko.Spec.Name = resp.ClusterName
	} else {
		ko.Spec.Name = nil
	}
	if resp.ClusterType != "" {
		ko.Status.Type = aws.String(string(resp.ClusterType))
	} else {
		ko.Status.Type = nil
	}
	if resp.State != "" {
		ko.Status.State = aws.String(string(resp.State))
	} else {
		ko.Status.State = nil
	}

	rm.setStatusDefaults(ko)
	if !serverlessClusterActive(&resource{ko}) {
		// This causes a requeue and scram secrets will be synced on the next
		// reconciliation loop
		ackcondition.SetSynced(&resource{ko}, corev1.ConditionFalse, nil, nil)
		return &resource{ko}, nil
	}
	return &resource{ko}, nil
}

// newCreateRequestPayload returns an SDK-specific struct for the HTTP request
// payload of the Create API call for the resource
func (rm *resourceManager) newCreateRequestPayload(
	ctx context.Context,
	r *resource,
) (*svcsdk.CreateClusterV2Input, error) {
	res := &svcsdk.CreateClusterV2Input{}

	if r.ko.Spec.Name != nil {
		res.ClusterName = r.ko.Spec.Name
	}
	if r.ko.Spec.Provisioned != nil {
		f1 := &svcsdktypes.ProvisionedRequest{}
		if r.ko.Spec.Provisioned.BrokerNodeGroupInfo != nil {
			f1f0 := &svcsdktypes.BrokerNodeGroupInfo{}
			if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.BrokerAZDistribution != nil {
				f1f0.BrokerAZDistribution = svcsdktypes.BrokerAZDistribution(*r.ko.Spec.Provisioned.BrokerNodeGroupInfo.BrokerAZDistribution)
			}
			if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.ClientSubnets != nil {
				f1f0.ClientSubnets = aws.ToStringSlice(r.ko.Spec.Provisioned.BrokerNodeGroupInfo.ClientSubnets)
			}
			if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.ConnectivityInfo != nil {
				f1f0f2 := &svcsdktypes.ConnectivityInfo{}
				if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.ConnectivityInfo.PublicAccess != nil {
					f1f0f2f0 := &svcsdktypes.PublicAccess{}
					if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.ConnectivityInfo.PublicAccess.Type != nil {
						f1f0f2f0.Type = r.ko.Spec.Provisioned.BrokerNodeGroupInfo.ConnectivityInfo.PublicAccess.Type
					}
					f1f0f2.PublicAccess = f1f0f2f0
				}
				f1f0.ConnectivityInfo = f1f0f2
			}
			if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.InstanceType != nil {
				f1f0.InstanceType = r.ko.Spec.Provisioned.BrokerNodeGroupInfo.InstanceType
			}
			if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.SecurityGroups != nil {
				f1f0.SecurityGroups = aws.ToStringSlice(r.ko.Spec.Provisioned.BrokerNodeGroupInfo.SecurityGroups)
			}
			if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.StorageInfo != nil {
				f1f0f5 := &svcsdktypes.StorageInfo{}
				if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.StorageInfo.EBSStorageInfo != nil {
					f1f0f5f0 := &svcsdktypes.EBSStorageInfo{}
					if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.StorageInfo.EBSStorageInfo.ProvisionedThroughput != nil {
						f1f0f5f0f0 := &svcsdktypes.ProvisionedThroughput{}
						if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.StorageInfo.EBSStorageInfo.ProvisionedThroughput.Enabled != nil {
							f1f0f5f0f0.Enabled = r.ko.Spec.Provisioned.BrokerNodeGroupInfo.StorageInfo.EBSStorageInfo.ProvisionedThroughput.Enabled
						}
						if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.StorageInfo.EBSStorageInfo.ProvisionedThroughput.VolumeThroughput != nil {
							volumeThroughputCopy0 := *r.ko.Spec.Provisioned.BrokerNodeGroupInfo.StorageInfo.EBSStorageInfo.ProvisionedThroughput.VolumeThroughput
							if volumeThroughputCopy0 > math.MaxInt32 || volumeThroughputCopy0 < math.MinInt32 {
								return nil, fmt.Errorf("error: field VolumeThroughput is of type int32")
							}
							volumeThroughputCopy := int32(volumeThroughputCopy0)
							f1f0f5f0f0.VolumeThroughput = &volumeThroughputCopy
						}
						f1f0f5f0.ProvisionedThroughput = f1f0f5f0f0
					}
					if r.ko.Spec.Provisioned.BrokerNodeGroupInfo.StorageInfo.EBSStorageInfo.VolumeSize != nil {
						volumeSizeCopy0 := *r.ko.Spec.Provisioned.BrokerNodeGroupInfo.StorageInfo.EBSStorageInfo.VolumeSize
						if volumeSizeCopy0 > math.MaxInt32 || volumeSizeCopy0 < math.MinInt32 {
							return nil, fmt.Errorf("error: field VolumeSize is of type int32")
						}
						volumeSizeCopy := int32(volumeSizeCopy0)
						f1f0f5f0.VolumeSize = &volumeSizeCopy
					}
					f1f0f5.EbsStorageInfo = f1f0f5f0
				}
				f1f0.StorageInfo = f1f0f5
			}
			f1.BrokerNodeGroupInfo = f1f0
		}
		if r.ko.Spec.Provisioned.ClientAuthentication != nil {
			f1f1 := &svcsdktypes.ClientAuthentication{}
			if r.ko.Spec.Provisioned.ClientAuthentication.SASL != nil {
				f1f1f0 := &svcsdktypes.Sasl{}
				if r.ko.Spec.Provisioned.ClientAuthentication.SASL.IAM != nil {
					f1f1f0f0 := &svcsdktypes.Iam{}
					if r.ko.Spec.Provisioned.ClientAuthentication.SASL.IAM.Enabled != nil {
						f1f1f0f0.Enabled = r.ko.Spec.Provisioned.ClientAuthentication.SASL.IAM.Enabled
					}
					f1f1f0.Iam = f1f1f0f0
				}
				if r.ko.Spec.Provisioned.ClientAuthentication.SASL.SCRAM != nil {
					f1f1f0f1 := &svcsdktypes.Scram{}
					if r.ko.Spec.Provisioned.ClientAuthentication.SASL.SCRAM.Enabled != nil {
						f1f1f0f1.Enabled = r.ko.Spec.Provisioned.ClientAuthentication.SASL.SCRAM.Enabled
					}
					f1f1f0.Scram = f1f1f0f1
				}
				f1f1.Sasl = f1f1f0
			}
			if r.ko.Spec.Provisioned.ClientAuthentication.TLS != nil {
				f1f1f1 := &svcsdktypes.Tls{}
				if r.ko.Spec.Provisioned.ClientAuthentication.TLS.CertificateAuthorityARNList != nil {
					f1f1f1.CertificateAuthorityArnList = aws.ToStringSlice(r.ko.Spec.Provisioned.ClientAuthentication.TLS.CertificateAuthorityARNList)
				}
				if r.ko.Spec.Provisioned.ClientAuthentication.TLS.Enabled != nil {
					f1f1f1.Enabled = r.ko.Spec.Provisioned.ClientAuthentication.TLS.Enabled
				}
				f1f1.Tls = f1f1f1
			}
			if r.ko.Spec.Provisioned.ClientAuthentication.Unauthenticated != nil {
				f1f1f2 := &svcsdktypes.Unauthenticated{}
				if r.ko.Spec.Provisioned.ClientAuthentication.Unauthenticated.Enabled != nil {
					f1f1f2.Enabled = r.ko.Spec.Provisioned.ClientAuthentication.Unauthenticated.Enabled
				}
				f1f1.Unauthenticated = f1f1f2
			}
			f1.ClientAuthentication = f1f1
		}
		if r.ko.Spec.Provisioned.ConfigurationInfo != nil {
			f1f2 := &svcsdktypes.ConfigurationInfo{}
			if r.ko.Spec.Provisioned.ConfigurationInfo.ARN != nil {
				f1f2.Arn = r.ko.Spec.Provisioned.ConfigurationInfo.ARN
			}
			if r.ko.Spec.Provisioned.ConfigurationInfo.Revision != nil {
				f1f2.Revision = r.ko.Spec.Provisioned.ConfigurationInfo.Revision
			}
			f1.ConfigurationInfo = f1f2
		}
		if r.ko.Spec.Provisioned.EncryptionInfo != nil {
			f1f3 := &svcsdktypes.EncryptionInfo{}
			if r.ko.Spec.Provisioned.EncryptionInfo.EncryptionAtRest != nil {
				f1f3f0 := &svcsdktypes.EncryptionAtRest{}
				if r.ko.Spec.Provisioned.EncryptionInfo.EncryptionAtRest.DataVolumeKMSKeyID != nil {
					f1f3f0.DataVolumeKMSKeyId = r.ko.Spec.Provisioned.EncryptionInfo.EncryptionAtRest.DataVolumeKMSKeyID
				}
				f1f3.EncryptionAtRest = f1f3f0
			}
			if r.ko.Spec.Provisioned.EncryptionInfo.EncryptionInTransit != nil {
				f1f3f1 := &svcsdktypes.EncryptionInTransit{}
				if r.ko.Spec.Provisioned.EncryptionInfo.EncryptionInTransit.ClientBroker != nil {
					f1f3f1.ClientBroker = svcsdktypes.ClientBroker(*r.ko.Spec.Provisioned.EncryptionInfo.EncryptionInTransit.ClientBroker)
				}
				if r.ko.Spec.Provisioned.EncryptionInfo.EncryptionInTransit.InCluster != nil {
					f1f3f1.InCluster = r.ko.Spec.Provisioned.EncryptionInfo.EncryptionInTransit.InCluster
				}
				f1f3.EncryptionInTransit = f1f3f1
			}
			f1.EncryptionInfo = f1f3
		}
		if r.ko.Spec.Provisioned.EnhancedMonitoring != nil {
			f1.EnhancedMonitoring = svcsdktypes.EnhancedMonitoring(*r.ko.Spec.Provisioned.EnhancedMonitoring)
		}
		if r.ko.Spec.Provisioned.KafkaVersion != nil {
			f1.KafkaVersion = r.ko.Spec.Provisioned.KafkaVersion
		}
		if r.ko.Spec.Provisioned.LoggingInfo != nil {
			f1f6 := &svcsdktypes.LoggingInfo{}
			if r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs != nil {
				f1f6f0 := &svcsdktypes.BrokerLogs{}
				if r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.CloudWatchLogs != nil {
					f1f6f0f0 := &svcsdktypes.CloudWatchLogs{}
					if r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.CloudWatchLogs.Enabled != nil {
						f1f6f0f0.Enabled = r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.CloudWatchLogs.Enabled
					}
					if r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.CloudWatchLogs.LogGroup != nil {
						f1f6f0f0.LogGroup = r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.CloudWatchLogs.LogGroup
					}
					f1f6f0.CloudWatchLogs = f1f6f0f0
				}
				if r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.Firehose != nil {
					f1f6f0f1 := &svcsdktypes.Firehose{}
					if r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.Firehose.DeliveryStream != nil {
						f1f6f0f1.DeliveryStream = r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.Firehose.DeliveryStream
					}
					if r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.Firehose.Enabled != nil {
						f1f6f0f1.Enabled = r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.Firehose.Enabled
					}
					f1f6f0.Firehose = f1f6f0f1
				}
				if r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.S3 != nil {
					f1f6f0f2 := &svcsdktypes.S3{}
					if r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.S3.Bucket != nil {
						f1f6f0f2.Bucket = r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.S3.Bucket
					}
					if r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.S3.Enabled != nil {
						f1f6f0f2.Enabled = r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.S3.Enabled
					}
					if r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.S3.Prefix != nil {
						f1f6f0f2.Prefix = r.ko.Spec.Provisioned.LoggingInfo.BrokerLogs.S3.Prefix
					}
					f1f6f0.S3 = f1f6f0f2
				}
				f1f6.BrokerLogs = f1f6f0
			}
			f1.LoggingInfo = f1f6
		}
		if r.ko.Spec.Provisioned.NumberOfBrokerNodes != nil {
			numberOfBrokerNodesCopy0 := *r.ko.Spec.Provisioned.NumberOfBrokerNodes
			if numberOfBrokerNodesCopy0 > math.MaxInt32 || numberOfBrokerNodesCopy0 < math.MinInt32 {
				return nil, fmt.Errorf("error: field NumberOfBrokerNodes is of type int32")
			}
			numberOfBrokerNodesCopy := int32(numberOfBrokerNodesCopy0)
			f1.NumberOfBrokerNodes = &numberOfBrokerNodesCopy
		}
		if r.ko.Spec.Provisioned.OpenMonitoring != nil {
			f1f8 := &svcsdktypes.OpenMonitoringInfo{}
			if r.ko.Spec.Provisioned.OpenMonitoring.Prometheus != nil {
				f1f8f0 := &svcsdktypes.PrometheusInfo{}
				if r.ko.Spec.Provisioned.OpenMonitoring.Prometheus.JmxExporter != nil {
					f1f8f0f0 := &svcsdktypes.JmxExporterInfo{}
					if r.ko.Spec.Provisioned.OpenMonitoring.Prometheus.JmxExporter.EnabledInBroker != nil {
						f1f8f0f0.EnabledInBroker = r.ko.Spec.Provisioned.OpenMonitoring.Prometheus.JmxExporter.EnabledInBroker
					}
					f1f8f0.JmxExporter = f1f8f0f0
				}
				if r.ko.Spec.Provisioned.OpenMonitoring.Prometheus.NodeExporter != nil {
					f1f8f0f1 := &svcsdktypes.NodeExporterInfo{}
					if r.ko.Spec.Provisioned.OpenMonitoring.Prometheus.NodeExporter.EnabledInBroker != nil {
						f1f8f0f1.EnabledInBroker = r.ko.Spec.Provisioned.OpenMonitoring.Prometheus.NodeExporter.EnabledInBroker
					}
					f1f8f0.NodeExporter = f1f8f0f1
				}
				f1f8.Prometheus = f1f8f0
			}
			f1.OpenMonitoring = f1f8
		}
		if r.ko.Spec.Provisioned.StorageMode != nil {
			f1.StorageMode = svcsdktypes.StorageMode(*r.ko.Spec.Provisioned.StorageMode)
		}
		res.Provisioned = f1
	}
	if r.ko.Spec.Serverless != nil {
		f2 := &svcsdktypes.ServerlessRequest{}
		if r.ko.Spec.Serverless.ClientAuthentication != nil {
			f2f0 := &svcsdktypes.ServerlessClientAuthentication{}
			if r.ko.Spec.Serverless.ClientAuthentication.SASL != nil {
				f2f0f0 := &svcsdktypes.ServerlessSasl{}
				if r.ko.Spec.Serverless.ClientAuthentication.SASL.IAM != nil {
					f2f0f0f0 := &svcsdktypes.Iam{}
					if r.ko.Spec.Serverless.ClientAuthentication.SASL.IAM.Enabled != nil {
						f2f0f0f0.Enabled = r.ko.Spec.Serverless.ClientAuthentication.SASL.IAM.Enabled
					}
					f2f0f0.Iam = f2f0f0f0
				}
				f2f0.Sasl = f2f0f0
			}
			f2.ClientAuthentication = f2f0
		}
		if r.ko.Spec.Serverless.VPCConfigs != nil {
			f2f1 := []svcsdktypes.VpcConfig{}
			for _, f2f1iter := range r.ko.Spec.Serverless.VPCConfigs {
				f2f1elem := &svcsdktypes.VpcConfig{}
				if f2f1iter.SecurityGroupIDs != nil {
					f2f1elem.SecurityGroupIds = aws.ToStringSlice(f2f1iter.SecurityGroupIDs)
				}
				if f2f1iter.SubnetIDs != nil {
					f2f1elem.SubnetIds = aws.ToStringSlice(f2f1iter.SubnetIDs)
				}
				f2f1 = append(f2f1, *f2f1elem)
			}
			f2.VpcConfigs = f2f1
		}
		res.Serverless = f2
	}
	if r.ko.Spec.Tags != nil {
		res.Tags = aws.ToStringMap(r.ko.Spec.Tags)
	}

	return res, nil
}

// sdkUpdate patches the supplied resource in the backend AWS service API and
// returns a new resource with updated fields.
func (rm *resourceManager) sdkUpdate(
	ctx context.Context,
	desired *resource,
	latest *resource,
	delta *ackcompare.Delta,
) (*resource, error) {
	return rm.customUpdate(ctx, desired, latest, delta)
}

// sdkDelete deletes the supplied resource in the backend AWS service API
func (rm *resourceManager) sdkDelete(
	ctx context.Context,
	r *resource,
) (latest *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkDelete")
	defer func() {
		exit(err)
	}()
	return rm.customDelete(ctx, r)
}

// setStatusDefaults sets default properties into supplied custom resource
func (rm *resourceManager) setStatusDefaults(
	ko *svcapitypes.ServerlessCluster,
) {
	if ko.Status.ACKResourceMetadata == nil {
		ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if ko.Status.ACKResourceMetadata.Region == nil {
		ko.Status.ACKResourceMetadata.Region = &rm.awsRegion
	}
	if ko.Status.ACKResourceMetadata.OwnerAccountID == nil {
		ko.Status.ACKResourceMetadata.OwnerAccountID = &rm.awsAccountID
	}
	if ko.Status.Conditions == nil {
		ko.Status.Conditions = []*ackv1alpha1.Condition{}
	}
}

// updateConditions returns updated resource, true; if conditions were updated
// else it returns nil, false
func (rm *resourceManager) updateConditions(
	r *resource,
	onSuccess bool,
	err error,
) (*resource, bool) {
	ko := r.ko.DeepCopy()
	rm.setStatusDefaults(ko)

	// Terminal condition
	var terminalCondition *ackv1alpha1.Condition = nil
	var recoverableCondition *ackv1alpha1.Condition = nil
	var syncCondition *ackv1alpha1.Condition = nil
	for _, condition := range ko.Status.Conditions {
		if condition.Type == ackv1alpha1.ConditionTypeTerminal {
			terminalCondition = condition
		}
		if condition.Type == ackv1alpha1.ConditionTypeRecoverable {
			recoverableCondition = condition
		}
		if condition.Type == ackv1alpha1.ConditionTypeResourceSynced {
			syncCondition = condition
		}
	}
	var termError *ackerr.TerminalError
	if rm.terminalAWSError(err) || err == ackerr.SecretTypeNotSupported || err == ackerr.SecretNotFound || errors.As(err, &termError) {
		if terminalCondition == nil {
			terminalCondition = &ackv1alpha1.Condition{
				Type: ackv1alpha1.ConditionTypeTerminal,
			}
			ko.Status.Conditions = append(ko.Status.Conditions, terminalCondition)
		}
		var errorMessage = ""
		if err == ackerr.SecretTypeNotSupported || err == ackerr.SecretNotFound || errors.As(err, &termError) {
			errorMessage = err.Error()
		} else {
			awsErr, _ := ackerr.AWSError(err)
			errorMessage = awsErr.Error()
		}
		terminalCondition.Status = corev1.ConditionTrue
		terminalCondition.Message = &errorMessage
	} else {
		// Clear the terminal condition if no longer present
		if terminalCondition != nil {
			terminalCondition.Status = corev1.ConditionFalse
			terminalCondition.Message = nil
		}
		// Handling Recoverable Conditions
		if err != nil {
			if recoverableCondition == nil {
				// Add a new Condition containing a non-terminal error
				recoverableCondition = &ackv1alpha1.Condition{
					Type: ackv1alpha1.ConditionTypeRecoverable,
				}
				ko.Status.Conditions = append(ko.Status.Conditions, recoverableCondition)
			}
			recoverableCondition.Status = corev1.ConditionTrue
			awsErr, _ := ackerr.AWSError(err)
			errorMessage := err.Error()
			if awsErr != nil {
				errorMessage = awsErr.Error()
			}
			recoverableCondition.Message = &errorMessage
		} else if recoverableCondition != nil {
			recoverableCondition.Status = corev1.ConditionFalse
			recoverableCondition.Message = nil
		}
	}
	// Required to avoid the "declared but not used" error in the default case
	_ = syncCondition
	if terminalCondition != nil || recoverableCondition != nil || syncCondition != nil {
		return &resource{ko}, true // updated
	}
	return nil, false // not updated
}

// terminalAWSError returns awserr, true; if the supplied error is an aws Error type
// and if the exception indicates that it is a Terminal exception
// 'Terminal' exception are specified in generator configuration
func (rm *resourceManager) terminalAWSError(err error) bool {
	// No terminal_errors specified for this resource in generator config
	return false
}
